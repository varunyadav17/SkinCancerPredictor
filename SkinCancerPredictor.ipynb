{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SkinCancerPredictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/varunyadav17/SkinCancerPredictor/blob/master/SkinCancerPredictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH67p643CvoA",
        "colab_type": "code",
        "outputId": "5a6cb5d9-7040-426f-e3aa-81c0509b79f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        }
      },
      "source": [
        "!pip install pyunpack patool\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pyunpack import Archive\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyunpack\n",
            "  Downloading https://files.pythonhosted.org/packages/79/dc/44cd41fb99d184ae7c2eac439a52ca624d5ece62b0302c3437fcc4ce3b58/pyunpack-0.1.2.tar.gz\n",
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hCollecting easyprocess (from pyunpack)\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/29/40040d1d64a224a5e44df9572794a66494618ffe5c77199214aeceedb8a7/EasyProcess-0.2.7-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: pyunpack\n",
            "  Building wheel for pyunpack (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyunpack: filename=pyunpack-0.1.2-cp36-none-any.whl size=5162 sha256=3f4f7d7bef52f21e83699a6ae1c085de6e20274be205e2f4c12171f7edfd74ef\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/44/08/60613970881e542c0baad1f2dea5ed8e6716bc573f49197b7e\n",
            "Successfully built pyunpack\n",
            "Installing collected packages: easyprocess, pyunpack, patool\n",
            "Successfully installed easyprocess-0.2.7 patool-1.12 pyunpack-0.1.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxoD03gReHJi",
        "colab_type": "code",
        "outputId": "c19c5582-5c1f-4332-e720-3cc8d76406ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MejB9D9hLZ-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Archive('/content/drive/My Drive/Data.rar').extractall('.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2sm24OiQbnA",
        "colab_type": "text"
      },
      "source": [
        "**Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9U5Cff9QdN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "count = len(os.listdir('Data'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om_1fIx_Q9TD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DESC_PATH = 'Data/Descriptions/'\n",
        "INPUT_IMAGE_PATH = 'Data/Images'\n",
        "if count > 0 and os.path.exists(INPUT_DESC_PATH):\n",
        "  descfiles = os.listdir(INPUT_DESC_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdJQFVXCgDC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#descfiles = [i[:-5] for i in descfiles if i.endswith('.json')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETTtszctRVxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_types = {}\n",
        "if len(descfiles) > 0:\n",
        "  for i in range(len(descfiles)):\n",
        "    file = os.path.join(INPUT_DESC_PATH, descfiles[i])\n",
        "    with open(file) as json_file:\n",
        "      data = json.load(json_file)\n",
        "      if descfiles[i].endswith('.json'):\n",
        "        key = descfiles[i][:-5]\n",
        "      else:\n",
        "        key = descfiles[i]\n",
        "      image_types[key] = data['meta']['clinical']['benign_malignant']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWnW58Bu1n_P",
        "colab_type": "text"
      },
      "source": [
        "**Create Directory Tree**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN5BVaxo1drB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('Train'):\n",
        "  os.mkdir('Train')\n",
        "  os.chdir('Train')\n",
        "  os.mkdir('Benign')\n",
        "  os.mkdir('Malignant')\n",
        "  \n",
        "if not os.path.exists('Test'):\n",
        "  os.chdir('..')\n",
        "  os.mkdir('Test') \n",
        "  os.chdir('Test')\n",
        "  os.mkdir('Benign')\n",
        "  os.mkdir('Malignant')\n",
        "  \n",
        "if not os.path.exists('Val'):\n",
        "  os.chdir('..')\n",
        "  os.mkdir('Val')\n",
        "  os.chdir('Val')\n",
        "  os.mkdir('Benign')\n",
        "  os.mkdir('Malignant')\n",
        "  os.chdir('..')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGK8XIdrSMcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "benign_images = [key for (key, value) in image_types.items() if value == 'benign']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kjj8U6bFVj86",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append extensions to files\n",
        "complete_benign_files = []\n",
        "input_files = os.listdir(INPUT_IMAGE_PATH)\n",
        "for i in range(len(benign_images)):\n",
        "  newfile = [file for file in input_files if file.startswith(benign_images[i])]\n",
        "  complete_benign_files.append(newfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjWuV7io3jv6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "malignant_images = [key for (key, value) in image_types.items() if value == 'malignant']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBE8P0KqarSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Append extensions to files\n",
        "complete_malignant_files = []\n",
        "input_files = os.listdir(INPUT_IMAGE_PATH)\n",
        "for i in range(len(malignant_images)):\n",
        "  newfile = [file for file in input_files if file.startswith(malignant_images[i])]\n",
        "  complete_malignant_files.append(newfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqCj2H1g4wzM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, val, test = np.split(pd.DataFrame(complete_benign_files).sample(frac = 1) ,[int(.6 * len(complete_benign_files)), int(.8 * len(complete_benign_files))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJIL5C4bE85G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move benign files to their respective directories\n",
        "train_list = train[0].tolist()\n",
        "for i in range(len(train)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (train_list[i]))\n",
        "  dest = os.path.join('Train/Benign', train_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)\n",
        "    \n",
        "test_list = test[0].tolist()\n",
        "for i in range(len(test)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (test_list[i]))\n",
        "  dest = os.path.join('Test/Benign', test_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)\n",
        "\n",
        "val_list = val[0].tolist()\n",
        "for i in range(len(val)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (val_list[i]))\n",
        "  dest = os.path.join('Val/Benign', val_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQJ60qv0gfBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now add malignant files in similar ratio to Train,Test and Val directories\n",
        "train, val, test = np.split(pd.DataFrame(complete_malignant_files).sample(frac = 1) ,[int(.6 * len(complete_malignant_files)), int(.8 * len(complete_malignant_files))])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB6UZ9JGgxtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Move malignant files to their respective directories\n",
        "train_list = train[0].tolist()\n",
        "for i in range(len(train)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (train_list[i]))\n",
        "  dest = os.path.join('Train/Malignant', train_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)\n",
        "    \n",
        "test_list = test[0].tolist()\n",
        "for i in range(len(test)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (test_list[i]))\n",
        "  dest = os.path.join('Test/Malignant', test_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)\n",
        "\n",
        "val_list = val[0].tolist()\n",
        "for i in range(len(val)):\n",
        "  src = os.path.join(INPUT_IMAGE_PATH, (val_list[i]))\n",
        "  dest = os.path.join('Val/Malignant', val_list[i])\n",
        "  if os.path.exists(src):\n",
        "    shutil.move(src, dest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aXo7Om0h1AV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.rmtree('Data')\n",
        "#os.remove('TestData.rar')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vre7_zTQQCGd",
        "colab_type": "text"
      },
      "source": [
        "**Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErTOrHZjQwoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 2\n",
        "if not os.path.exists('Output'):\n",
        "  os.mkdir('Output')\n",
        "  os.chdir('Output')\n",
        "  os.mkdir('Models')\n",
        "  os.mkdir('Logs')\n",
        "  os.chdir('..')\n",
        "model_file = 'Models' + '_{}'.format(datetime.datetime.now())\n",
        "log_dir = 'Output/Logs'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYVbfY4RQEbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = ModelCheckpoint(model_file, monitor = 'val_acc', save_best_only = True)\n",
        "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 5, verbose = 1, restore_best_weights = True)\n",
        "tensorboard = TensorBoard(log_dir = log_dir, batch_size = batch_size, update_freq = 'batch')\n",
        "reduce_lr = ReduceLROnPlateau(monitor= 'val_loss', patience = 5, cooldown = 2, lr = 0.0000000001, verbose = 1)\n",
        "\n",
        "callbacks = [checkpoint, early_stopping, tensorboard, reduce_lr]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3Z6H3MphNnx",
        "colab_type": "text"
      },
      "source": [
        "**Model Building**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQ-gLE6G1nOH",
        "colab_type": "code",
        "outputId": "26cee662-0e56-4f2a-bed8-652577125f55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same', input_shape = (32, 32, 3)))\n",
        "model.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(64, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(96, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(96, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(Conv2D(128, (3, 3), activation = 'relu', padding = 'same'))\n",
        "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "          \n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation = 'relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation = 'sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 8, 8, 96)          55392     \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 8, 8, 96)          83040     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 4, 4, 128)         110720    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 495,201\n",
            "Trainable params: 495,201\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOe4sQEjSvV6",
        "colab_type": "code",
        "outputId": "60dd6642-74e3-4c57-b80c-08367c85823e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WP_OLsdGhP9f",
        "colab_type": "code",
        "outputId": "204847b6-fa88-45da-dbf2-b4986ffb8776",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "train_generator = train_datagen.flow_from_directory('Train', target_size = (32, 32), batch_size = batch_size, class_mode = 'binary')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_generator = test_datagen.flow_from_directory('Test', target_size = (32, 32), batch_size = batch_size, class_mode = 'binary')\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "val_generator = val_datagen.flow_from_directory('Val', target_size = (32, 32), batch_size = batch_size, class_mode = 'binary')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 840 images belonging to 2 classes.\n",
            "Found 280 images belonging to 2 classes.\n",
            "Found 280 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqSbyArsd1Ce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_class_weight('balanced', np.unique(train_generator.classes), train_generator.classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukoRoOpgeUz5",
        "colab_type": "code",
        "outputId": "1ae3e5f2-887a-4feb-fafe-1ddec70f1432",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "class_weight"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.7 , 1.75])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egXa6dxLwbUz",
        "colab_type": "code",
        "outputId": "26312bfe-03a9-4085-d4c3-7922c390c4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "model.fit_generator(train_generator, steps_per_epoch = len(train_generator), epochs = 100, validation_data = val_generator, validation_steps = len(val_generator), \n",
        "                    callbacks = callbacks, class_weight = class_weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/100\n",
            "420/420 [==============================] - 99s 235ms/step - loss: 1.6858 - acc: 0.7095 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 2/100\n",
            "420/420 [==============================] - 96s 230ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 3/100\n",
            "420/420 [==============================] - 97s 231ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 4/100\n",
            "420/420 [==============================] - 92s 219ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 5/100\n",
            "420/420 [==============================] - 94s 224ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 6/100\n",
            "420/420 [==============================] - 93s 222ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 7/100\n",
            "420/420 [==============================] - 93s 221ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Epoch 8/100\n",
            "420/420 [==============================] - 94s 224ms/step - loss: 4.6052 - acc: 0.7143 - val_loss: 4.6052 - val_acc: 0.7143\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00008: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe77f2a7518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SshY8MuwOGob",
        "colab_type": "code",
        "outputId": "5503e422-4559-416d-a99f-0636ed370ed9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "results = model.evaluate_generator(test_generator, steps = len(test_generator), verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140/140 [==============================] - 21s 152ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBEruZF_OVFP",
        "colab_type": "code",
        "outputId": "c5a83d49-8e1b-4934-c900-641d059c5f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(\"Loss = %s\" %results[0])\n",
        "print(\"Accuracy = %s\" %results[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loss = 4.6051701651283565\n",
            "Accuracy = 0.7142857142857143\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}